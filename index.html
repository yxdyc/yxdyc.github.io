<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Daoyuan Chen's Homepage</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i, Raleway:300,300i,400,400i,500,500i,600,600i,700,700i, Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/animate.css/animate.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <style>
    li {
      margin: 10px 10px 10px 10px;
    }
  </style>

  <style>
    blockquote {
      border-left: 5px solid #ccc;
      padding-left: 15px;
      margin: 20px 0;
      font-style: italic;
      color: #555;
    }

    blockquote p {
      margin: 0;
    }
  </style>


  <!-- =======================================================
    Modified based on the following template.
  * Template Name: Selecao - v4.6.0
  * Template URL: https://bootstrapmade.com/selecao-bootstrap-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>


<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top d-flex align-items-center  header-transparent ">
    <div class="container d-flex align-items-center justify-content-between">

      <div class="logo">


        <h6><a href="https://yxdyc.github.io/" target="blank_" style="color: #ffffff; font-weight: bold;">Daoyuan Chen
            (陈道源)</a></h6>
      </div>

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto active" href="#about" style="font-weight: bold;">About</a></li>
          <li><a class="nav-link scrollto" href="#research" style="font-weight: bold;">Selected Research</a></li>
          <li><a class="nav-link scrollto" href="#experience" style="font-weight: bold;">Working Experiences</a></li>
          <li><a class="nav-link scrollto" href="#activities" style="font-weight: bold;">Professional Activities</a>
          </li>
          <li><a class="nav-link scrollto" href="#misc" style="font-weight: bold;">Misc</a></li>
          <li><a class="nav-link scrollto" href="#contact" style="font-weight: bold;">Contact</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <!-- ======= Header Wrapper Section ======= -->
  <section id="hero" class="d-flex flex-column justify-content-end align-items-center">
    <style>
      #hero {
        height: 10vh;
        padding-top: 5px;
        padding-bottom: 0px;
      }

      .hero-waves {
        height: 80px;
      }
    </style>
    <svg class="hero-waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
      viewBox="0 24 150 28 " preserveAspectRatio="none">
      <defs>
        <path id="wave-path" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z">
      </defs>
      <g class="wave1">
        <use xlink:href="#wave-path" x="50" y="3" fill="rgba(173, 216, 230, 0.3)"></use> <!-- 浅蓝色 -->
      </g>
      <g class="wave2">
        <use xlink:href="#wave-path" x="50" y="0" fill="rgba(135, 206, 250, 0.5)"></use> <!-- 天蓝色 -->
      </g>
      <g class="wave3">
        <use xlink:href="#wave-path" x="50" y="9" fill="#fff" transform="scale(1, 0.5)"></use>
      </g>
    </svg>
  </section><!-- End Header Wrapper -->

  <main id="main">

    <!-- ======= About Section ======= -->
    <section id="about" class="about">
      <div class="container">

        <div class="section-title">
          <h2>About</h2>
          <p>Daoyuan Chen (陈道源)</p>
        </div>

        <div class="row content">
          <div class="col-lg-6 pt-4 pt-lg-0">
            <p>
              Hi, I'm doing research and development at Data Analytics and Intelligence Lab, Alibaba Tongyi.
              I earned my Master's degree in Computer Application Technology in June 2019 from Peking University,
              co-supervised by
              <a href="https://dblp.org/pid/01/8558-1.html">Ying Shen</a> and
              <a href="https://dblp.org/pid/64/9060.html">Kai Lei</a> (academic mentors), and <a
                href="https://sites.google.com/site/yaliangli/">Yaliang Li</a> (industry mentor).
            </p>
            <br>
            <p>
              I've published over 30 technical papers, more than 10 of which I've led as the first author and were
              presented at top-tier conferences such as ICML, NeurIPS, ICLR, SIGMOD, KDD, ACL and SIGIR.
            </p>
            <br>
            <p>
              I’m glad to have the opportunity to be founding/core contributor for several open-source projects:
            </p>
            <ul>
              <li>
                (1) <strong><a href="https://github.com/modelscope/data-juicer">Data-Juicer</a></strong>: data
                processing for and with foundation models. <iframe
                  src="https://ghbtns.com/github-btn.html?user=modelscope&repo=data-juicer&type=star&count=true"
                  frameborder="0" scrolling="0" width="170" height="30" title="GitHub">
                </iframe>
              </li>
              <li>
                (2) <a href="https://github.com/alibaba/FederatedScope">FederatedScope</a>: an easy-to-use FL platform.
                <iframe src="https://ghbtns.com/github-btn.html?user=alibaba&repo=FederatedScope&type=star&count=true"
                  frameborder="0" scrolling="0" width="170" height="30" title="GitHub">
                </iframe>
              </li>
              <li>
                (3) <a href="https://github.com/modelscope/agentscope">AgentScope</a>: a multi-agent LLM platform.
                <iframe src="https://ghbtns.com/github-btn.html?user=modelscope&repo=agentscope&type=star&count=true"
                  frameborder="0" scrolling="0" width="170" height="30" title="GitHub">
                </iframe>
              </li>
            </ul>
            <br>
            <p>Collaborations and self-motivated interns are welcome! Feel free to
              <a href="#contact" style="font-weight: bold;">
                reach out</a>
            </p> if you are interested.
          </div>

          <div class="col-lg-6 pt-4 pt-lg-0">
            <p><b>My interests broadly lie in research, systems, and their practical applications related to:</b></p>
            <ul>
              <li>•&emsp;Large Language Models (LLMs)</li>
              <li>•&emsp;Multimodal LLMs</li>
              <li>•&emsp;Efficient Machine Learning (ML)</li>
              <li>•&emsp;Data- and Knowledge-Driven ML</li>
              <li>•&emsp;Human-centric ML</li>
              <li>•&emsp;Federated Learning (FL)</li>
            </ul>

            <p>More specifically, including but not limited to:</p>
            <ul>
              <li>•&emsp;Data-model co-development, e.g., building infrastructures, and exploring <em>generalized</em>
                feedback signals</li>
              <li>•&emsp;Algorithms for enhancing data quality, diversity, and usability</li>
              <li>•&emsp;Synthetic data for model training and evaluation</li>
              <li>•&emsp;Better human-computer interaction, e.g., empathetic dialog, multimodal AIGC, and personalized
                modeling</li>
              <li>•&emsp;On-device solutions via utilizing small models, and addressing privacy issues with FL</li>
            </ul>
          </div>

        </div>
      </div>
    </section><!-- End About Section -->


    <!-- ======= Selected Research Section ======= -->
    <section id="research" class="faq">
      <div class="container">
        <div class="section-title">
          <h2>Selected</h2>
          <p>Research [<a href="https://scholar.google.com/citations?hl=en&amp;user=1GdfinUAAAAJ">Google Scholar</a> |
            <a href="https://dblp.org/pid/217/4891.html">DBLP</a>]
          </p>
        </div>

        <p>Remark: # indicates equal contribution to the first author; ^ indicates industrial mentor to the first
          student author.</p>

        <h4><b>(Multimodal) LLMs, Data-Driven & Human-Centric ML</b></h4>
        <ul>
          <li>[<em>arXiv’25</em>] <a href="https://www.arxiv.org/abs/2502.04380"><strong>Diversity as a Reward:
                Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data</strong></a>
            <ul>
              <li>Zhenqing Ling, <strong>Daoyuan Chen</strong>^#, Liuyi Yao, Yaliang Li, Ying Shen</li>
              <li><em>A theoretically informed method, which treats diversity as a reward, achieves new SOTA average
                  performance across 7 benchmarks on SOTA LLMs with domain-undetermined data.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2501.14755"><strong> Data-Juicer 2.0: Cloud-Scale
                Adaptive Data Processing for Foundation Models</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yilun Huang, Xuchen Pan, Nana Jiang, Haibin Wang, Ce Ge, Yushuo Chen,
                Wenhao Zhang, Zhijian Ma, Yilei Zhang, Jun Huang, Wei Lin, Yaliang Li, Bolin Ding, Jingren Zhou</li>
              <li><em>Offering efficient multimodal data processing abilities and seamless scalability for foundation
                  models.</em></li>
            </ul>
          </li>
          <li>[<strong><em>SIGMOD’24</em></strong>] <a href="https://arxiv.org/abs/2309.02033"><strong>Data-Juicer: A
                One-Stop Data Processing System for Large Language Models</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yilun Huang, Zhijian Ma, Hesen Chen, Xuchen Pan, Ce Ge, Dawei Gao,
                Yuexiang Xie, Zhaoyang Liu, Jinyang Gao, Yaliang Li, Bolin Ding, Jingren Zhou.</li>
              <li><em>Providing open, versatile data processing abilities to ease the creation and evaluation of diverse
                  data recipes for LLMs.
                </em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2407.11784"><strong> Data-Juicer Sandbox: A
                Feedback-Driven Suite for Multimodal Data-Model Co-development</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou
              </li>
              <li><em>A new middleware links data and model feedback, enabling high performance and low cost verified in
                  broad tasks. <strong>Top-1</strong> in VBench leaderboard.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’24, Tutorial</em></strong>] <a
              href="https://modelscope.github.io/data-juicer/_static/tutorial_kdd24.html"><strong>Multi-modal Data
                Processing for Foundation Models: Practical Guidances and Use Cases</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yaliang Li, Bolin Ding, The Data-Juicer Team</li>
              <li><em>Discussing practical skills in multi-modal data processing, to efficiently handle data variety,
                  quality, and scale for foundation models.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2407.08583">
              <strong>The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development
                Perspective</strong>
            </a>
            <ul>
              <li>Zhen Qin, <strong>Daoyuan Chen</strong>^#, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang
                Li, Shuiguang Deng</li>
              <li><em>Highlighting the current state and potential of co-development between data and multi-modal LLMs,
                  in a dual perspective.
                </em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://www.arxiv.org/abs/2502.04380">
              <strong>HumanVBench: Exploring Human-Centric Video Understanding Capabilities of MLLMs with Synthetic
                Benchmark Data</strong>
            </a>
            <ul>
              <li>Ting Zhou, <strong>Daoyuan Chen</strong>^, Qirui Jiao, Bolin Ding, Yaliang Li, Ying Shen</li>
              <li><em>A new benchmark to evaluate MLLMs on inner emotion recognition and outer behavioral
                  manifestations, advancing human-like understanding in video perception.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/pdf/2408.04594">
              <strong>Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models</strong>
            </a>
            <ul>
              <li>Qirui Jiao, <strong>Daoyuan Chen</strong>^, Yilun Huang, Yaliang Li, Ying Shen.</li>
              <li><em>A new method of contrastive data synthesis, creating a high-quality dataset that describes object
                  differences focusing on fine-grained regions in images.</em></li>
            </ul>
          </li>
          <li>[<strong><em>COLING’24</em></strong>] <a href="https://arxiv.org/abs/2403.11236"><strong>ChartThinker: A
                Contextual Chain-of-Thought Approach to Optimized Chart Summarization</strong></a>
            <ul>
              <li>Mengsha Liu, <strong>Daoyuan Chen</strong>^, Yaliang Li, Guian Fang and Ying Shen.</li>
              <li><em>Optimizing chart summarization by combining contextual reasoning and deep analysis, achieving
                  superior performance across multiple metrics.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2401.17981">
              <strong>From Training-Free to Adaptive: Empirical Insights into MLLMs' Understanding of Detection
                Information</strong>
            </a>
            <ul>
              <li>Qirui Jiao, <strong>Daoyuan Chen</strong>^, Yilun Huang, Yaliang Li, Ying Shen.</li>
              <li><em>Showing how adaptively fine-tuning MLLMs with textual detection information can boost performance
                  via extensive experiments.
                </em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2402.11505">
              <strong>A Bivariate Data Mixing Law for Language Model Pretraining</strong>
            </a>
            <ul>
              <li>Ce Ge, Zhijian Ma, <strong>Daoyuan Chen</strong>, Yaliang Li, Bolin Ding.</li>
              <li><em>A new bivariate data mixing law that models the joint scaling patterns of domain proportions and
                  data quantity in LLM pretraining.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2412.12888">
              <strong> ArtAug: Enhancing Text-to-Image Generation through Synthesis-Understanding Interaction</strong>
            </a>
            <ul>
              <li>Zhongjie Duan, Qianyi Zhao, Cen Chen, <strong>Daoyuan Chen</strong>, Wenmeng Zhou, Yaliang Li, Yingda
                Chen</li>
              <li><em>Enhancing text-to-image generation by iteratively integrating synthesis and understanding models,
                  improving aesthetics and efficiency without extra inference costs.</em></li>
            </ul>
          </li>
          <li>[<em>arXiv’24</em>] <a href="https://arxiv.org/abs/2402.14034">
              <strong>AgentScope: A Flexible yet Robust Multi-Agent Platform</strong>
            </a>
            <ul>
              <li>Dawei Gao, Zitao Li, Xuchen Pan, Weirui Kuang, Zhijian Ma, Bingchen Qian, Fei Wei, Wenhao Zhang,
                Yuexiang Xie, <strong>Daoyuan Chen</strong>, Liuyi Yao, Hongyi Peng, Zeyu Zhang, Lin Zhu, Chen Cheng,
                Hongzhu Shi, Yaliang Li, Bolin Ding, Jingren Zhou.</li>
              <li><em>Offering open and broad abilities to build LLM-empowered multi-agent applications in an easier
                  way.</em></li>
            </ul>
          </li>
        </ul>

        <h4 id="federated-learning-on-device-personalization-systems"> FL+LLM, On-device & Personalized FL</h4>
        <ul>
          <li>[<strong><em>NeurIPS’24</em></strong>] <a href="https://arxiv.org/abs/2402.11505"><strong>Federated
                Fine-tuning of Large Language Models under Heterogeneous Language Tasks and Client
                Resources</strong></a>
            <ul>
              <li>Jiamu Bai, <strong>Daoyuan Chen</strong>^#, Bingchen Qian, Liuyi Yao, Yaliang Li.</li>
              <li><em>An aggregation scheme for FL of LLMs that dynamically adjusts LoRA ranks to harness the full
                  potential of diverse client resources, enhancing generalization, and validated on thousands of
                  tasks.</em></li>
            </ul>
          </li>
          <li>[<strong><em>ICML’24</em></strong>] <a href="https://arxiv.org/abs/2312.06353">
              <strong>
                Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18
                Kilobytes</strong>
            </a>
            <ul>
              <li>Zhen Qin, <strong>Daoyuan Chen</strong>^, Bingchen Qian, Bolin Ding, Yaliang Li, Shuiguang Deng.</li>
              <li><em> A theory-informed method for federated full-parameter tuning of LLMs, which incurs &lt18KB
                  communication cost per round for a 3B LLM, meanwhile delivering SOTA accuracy.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’24</em></strong>] <a href="https://arxiv.org/abs/2402.05926">
              <strong>
                On the Convergence of Zeroth-Order Federated Tuning in Large Language Models
              </strong>
            </a>
            <ul>
              <li>Zhenqing Ling, <strong>Daoyuan Chen</strong>^, Liuyi Yao, Yaliang Li, Ying Shen.</li>
              <li><em>FedMeZO, a memory-efficient method for FL of LLMs that achieves faster convergence and reduced GPU
                  memory usage, backed by theoretical analysis and empirical validation.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’24</em></strong>] <a href="https://arxiv.org/abs/2309.00363">FederatedScope-LLM: A
              Comprehensive Package for Fine-tuning Large Language Models in Federated Learning</a>
            <ul>
              <li>Weirui Kuang, Bingchen Qian, Zitao Li, <strong>Daoyuan Chen</strong>, Dawei Gao, Xuchen Pan, Yuexiang
                Xie, Yaliang Li, Bolin Ding, Jingren Zhou.</li>
              <li><em>A new package designed to address the challenges of fine-tuning LLMs in FL.</em></li>
            </ul>
          </li>
          <li>[<strong><em>TKDE’24</em></strong>] <a href="https://dl.acm.org/doi/10.1109/TKDE.2024.3482448">
              <strong>Is Sharing Neighbor Generator in Federated Graph Learning Safe? </strong>
            </a>
            <ul>
              <li>Liuyi Yao, Zhen Wang, Yuexiang Xie, Yaliang Li, Weirui Kuang, <strong>Daoyuan Chen</strong>, Bolin
                Ding.</li>
              <li><em>Sharing neighbor generators in graph FL poses privacy risks, as it enables data reconstruction
                  attacks, highlighting the need for defense strategies.</em></li>
            </ul>
          </li>
          <li>[<strong><em>ICML’23</em></strong>] <a href="https://arxiv.org/abs/2305.02776">
              <strong>Efficient Personalized Federated Learning via Sparse Model-Adaptation</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Liuyi Yao, Dawei Gao, Yaliang Li, Bolin Ding.</li>
              <li><em>An efficient pFL method with theoretical analysis, which adaptively learns sparse local models,
                  and achieves SOTA accuracy with improved efficiency simultaneously.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’23</em></strong>] <a href="https://arxiv.org/abs/2303.13363">
              <strong>FS-Real: Towards Real-World Cross-Device Federated Learning</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Dawei Gao, Yuexiang Xie, Xuchen Pan, Zitao Li, Yaliang Li, Bolin Ding,
                Jingren Zhou.</li>
              <li><em>An efficient, scalable system for real-world cross-device FL, addressing challenges of
                  heterogeneous devices and large-scale training.</em></li>
            </ul>
          </li>
          <li>[<strong><em>VLDB’23</em></strong>] <a href="https://bolinding.github.io/papers/vldb23fsreal.pdf">
              <strong>FS-Real: A Real-World Cross-Device Federated Learning Platform</strong>
            </a>
            <ul>
              <li>Dawei Gao, <strong>Daoyuan Chen</strong>#, Zitao Li, Yuexiang Xie, Xuchen Pan, Yaliang Li, Bolin Ding,
                Jingren Zhou.</li>
              <li><em>Industrial use-cases of FS-Real, including phones and cars.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’23</em></strong>] <a href="https://arxiv.org/abs/2302.01677">
              <strong>Revisiting Personalized Federated Learning: Robustness Against Backdoor Attacks</strong>
            </a>
            <ul>
              <li>Zeyu Qin, Liuyi Yao, <strong>Daoyuan Chen</strong>, Yaliang Li, Bolin Ding, Minhao Cheng.</li>
              <li><em>Personalized FL with partial model-sharing boosts robustness against backdoor attacks, unlike full
                  model-sharing, offering insights for improved defense strategies.</em></li>
            </ul>
          </li>
          <li>[<strong><em>VLDB’23</em></strong>] <a href="https://arxiv.org/abs/2204.05011">
              <strong>FederatedScope: A Flexible Federated Learning Platform for Heterogeneity</strong>
            </a>
            <ul>
              <li>Yuexiang Xie, Zhen Wang, Dawei Gao, <strong>Daoyuan Chen</strong>, Liuyi Yao, Weirui Kuang, Yaliang
                Li, Bolin Ding, Jingren Zhou.</li>
              <li><em>An open package for FL research and development.</em></li>
            </ul>
          </li>
          <li>[<strong><em>NeurIPS’22</em></strong>] <a href="https://arxiv.org/abs/2206.03655">
              <strong>pFL-Bench: A Comprehensive Benchmark for Personalized Federated Learning</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Dawei Gao, Weirui Kuang, Yaliang Li, Bolin Ding.</li>
              <li><em>Benchmarking personalized FL, containing more than 10 datasets, 20 pFL methods, and systematic
                  evaluation with highlighted benefits and potential of pFL.</em></li>
            </ul>
          </li>
          <li>[<strong><em>KDD’22, Tutorial</em></strong>] <a href="https://joneswong.github.io/KDD22FLTutorial/">
              <strong>A Practical Introduction to Federated Learning</strong>
            </a>
            <ul>
              <li>Yaliang Li, Bolin Ding, Zhen Wang, Yuexiang Xie, Dawei Gao, Liuyi Yao, <strong>Daoyuan Chen</strong>,
                Weirui Kuang, Hongzhu Shi, Jingren Zhou</li>
              <li><em>Hands-on lessons on FL and FS package.</em></li>
            </ul>
          </li>
        </ul>

        <h4 id="efficient-machine-learning-adaptiveness-dynamics-applications">Efficient, Adaptive, & Knowledge-Driven
          ML</h4>
        <ul>
          <li>[<strong><em>SIGIR’24</em></strong>] <a href="https://arxiv.org/abs/2404.02505">
              <strong>Dynamic Demonstration
                Retrieval and Cognitive Understanding for Emotional Support Conversation</strong>
            </a>
            <ul>
              <li>Zhe Xu, <strong>Daoyuan Chen</strong>^, Jiayi Kuang, Zihao Yi, Yaliang Li, Ying Shen.</li>
              <li><em> Enhancing emotional support conversations by improving empathetic response generation and
                  comprehending implicit mental states.</em></li>
            </ul>
          </li>
          <li>[<strong><em>ICLR’23</em></strong>] <a href="https://openreview.net/forum?id=UiaUEICawgw">
              <strong>Learned Index with Dynamic $\epsilon$</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Wuchao Li, Yaliang Li, Bolin Ding, Kai Zeng, Defu Lian, Jingren Zhou.
              </li>
              <li><em>A mathematically-grounded learned index framework, which is efficient, based on theoretically
                  derived prediction error bounds, and pluggable to several SOTA learned index
                  methods.</em></li>
            </ul>
          </li>
          <li>[<em>TNNLS, 2023, IF 10.4</em>] <a href="https://pubmed.ncbi.nlm.nih.gov/34752410/">
              <strong>Knowledge-Based
                Reasoning Network for Relation Detection</strong>
            </a>
            <ul>
              <li>Ying Shen, Min Yang, Yaliang Li, Dong Wang, Haitao Zheng, <strong>Daoyuan Chen</strong>.</li>
            </ul>
          </li>
          <li>[<strong><em>ACL’20</em></strong>] <a href="https://arxiv.org/abs/2004.09930">
              <strong>Relabel the noise: joint
                extraction of entities and relations via cooperative multiagents</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yaliang Li, Kai Lei, Ying Shen.</li>
              <li><em>A cooperative multiagent method jointly extracts entities and relations by re-labeling noisy data,
                  addressing shifted label distribution and improving extraction performance.
                </em></li>
            </ul>
          </li>
          <li>[<strong><em>IJCAI’20</em></strong>] <a href="https://arxiv.org/abs/2001.04246">
              <strong>Adabert: Task-adaptive
                bert compression with differentiable neural architecture search</strong>
            </a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yaliang Li, Minghui Qiu, Zhen Wang, Bofang Li, Bolin Ding, Hongbo Deng,
                Jun Huang, Wei Lin, Jingren Zhou.</li>
              <li><em>Using differentiable neural architecture search to compress BERT into task-adaptive models,
                  achieving faster inference and smaller size while maintaining performance.</em></li>
            </ul>
          </li>
          <li>[<strong><em>CIKM’20</em></strong>] <a href="https://dl.acm.org/doi/10.1145/3340531.3411989">
              <strong>An Adaptive
                Embedding Framework for Heterogeneous Information Networks</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yaliang Li, Bolin Ding, Ying Shen.</li>
            </ul>
          </li>
          <li>[<strong><em>AAAI’20</em></strong>] <a href="https://arxiv.org/abs/1911.09801">
              <strong>Joint learning of answer
                selection and answer summary generation in community question answering</strong></a>
            <ul>
              <li>Yang Deng, Wai Lam, Yuexiang Xie, <strong>Daoyuan Chen</strong>, Yaliang Li, Min Yang, Ying Shen.</li>
            </ul>
          </li>
          <li>[<strong><em>CIKM’19</em></strong>] <a href="https://dl.acm.org/doi/10.1145/3357384.3358071">
              <strong>Knowledge-aware textual entailment with graph
                attention network</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Yaliang Li, Min Yang, Hai-Tao Zheng, Ying Shen.</li>
            </ul>
          </li>
          <li>[<strong><em>SIGIR’19</em></strong>] <a href="https://dl.acm.org/doi/abs/10.1145/3331184.3331328">
              <strong>Answer-enhanced Path-aware Relation Detection
                over Knowledge Base</strong></a>
            <ul>
              <li><strong>Daoyuan Chen</strong>, Min Yang, Hai-Tao Zheng, Yaliang Li, Ying Shen.</li>
            </ul>
          </li>
          <li>[<strong><em>COLING’18</em></strong>] <a href="https://aclanthology.org/C18-1036">
              <strong>Cooperative denoising
                for distantly supervised relation extraction</strong></a>
            <ul>
              <li>Kai Lei, <strong>Daoyuan Chen</strong>#, Yaliang Li, Nan Du, Min Yang, Wei Fan, Ying Shen.</li>
              <li> <strong><em>best paper <a
                      href="https://coling2018.org/index.html%3Fp=1558.html">nominations</a></em></strong></li>
            </ul>
          </li>
          <li>[<strong><em>SIGIR’18</em></strong>] <a href="https://dl.acm.org/doi/abs/10.1145/3209978.3210067">
              <strong>Ontology
                evaluation with path-based text-aware entropy computation</strong>
            </a>
            <ul>
              <li>Ying Shen, <strong>Daoyuan Chen</strong>#, Min Yang, Yaliang Li, Nan Du, Kai Lei.</li>
            </ul>
          </li>
          <li>[<em>Artificial intelligence in medicine, 2018, IF 7.5</em>] <a
              href="https://pubmed.ncbi.nlm.nih.gov/29433958/">
              <strong>An ontology-driven clinical decision support system
                (IDDAP) for infectious disease diagnosis and antibiotic prescription</strong>
            </a>
            <ul>
              <li>Ying Shen, Kaiqi Yuan, <strong>Daoyuan Chen</strong>, Joël Colloc, Min Yang, Yaliang Li, Kai Lei.</li>
            </ul>
          </li>
        </ul>
      </div>
    </section>
    <!-- End Selected Research Section -->

    <!-- ======= Experience Section ======= -->
    <section id="experience" class="faq">
      <div class="container">
        <div class="section-title">
          <h2>Working</h2>
          <p>Experiences</p>
        </div>
        <ul>
          <li>2023 - Now, Data Analytics and Intelligence Lab, Alibaba Tongyi</li>
          <li>July 2019 - 2023, Data Analytics and Intelligence Lab, Alibaba DAMO Academy</li>
          <li>Research Intern, March 2018 - June 2018, Tencent Medical AI Lab</li>
          <li>Research Assistant, October 2016 - August 2017, Multimedia Software Engineering Research Center @ City
            University of Hong Kong</li>
        </ul>
      </div>
    </section>
    <!-- End Experience Section -->



    <!-- ======= activities Section ======= -->
    <section id="activities" class="faq">
      <div class="container">
        <div class="section-title">
          <h2>Professional</h2>
          <p>Activities</p>
          <h6>Tutorial Organizer: </h6>
          <ul>
            <li>KDD 2022</li>
            <li>KDD 2024</li>
          </ul>

          <h6>Competition Organizer: data leaderboards for (multimodal) LLMs </h6>
          <ul>
            <li><a href="https://tianchi.aliyun.com/competition/entrance/532157">FT-Data Ranker</a></li>
            <li> <a href="https://tianchi.aliyun.com/competition/entrance/532174">BetterMixture</a></li>
            <li><a href="https://tianchi.aliyun.com/competition/entrance/532219">ModelScope-Sora</a></li>
            <li><a href="https://tianchi.aliyun.com/competition/entrance/532251">Better Synth</a></li>
          </ul>

          <h6>Competition Participant:</h6>
          <ul>
            <li>KDD Cup, AutoML-Graph Track, 4/149, 2020 (<a href="https://github.com/joneswong/AutoGraph">our
                solution</a>)</li>
          </ul>

          <h6>Conference Reviewer: </h6>
          <ul>
            <li>NeurIPS/ICML/ICLR (2022-2025)</li>
            <li>CVPR/ICCV/ECCV (2023-2025)</li>
            <li>COLM (2024-2025)</li>
            <li>KDD (2021-2024)</li>
            <li>ACL/EMNLP/NAACL (2021-2024)</li>
            <li>IJCAI/CIKM (2021-2022)</li>
            </li>
          </ul>
          <h6>Journal Reviewer: </h6>
          <ul>
            <li>Expert Systems with Applications</li>
            <li>Neurocomputing</li>
            <li>Neural Networks</li>
            <li>Knowledge-Based Systems </li>
            <li>IEEE Transactions on Big Data </li>
            <li>Patterns </li>
            <li>Artificial Intelligence (AIJ) </li>
            <li>Artificial Intelligence In Medicine</li>
          </ul>

        </div>
      </div>
    </section><!-- End activities Section -->


    <!-- ======= misc Section ======= -->
    <section id="misc" class="faq">
      <div class="container">
        <div class="section-title">
          <h2></h2>
          <p>Misc.</p>

        </div>

        <blockquote>
          <h6>Creativity is intelligence having fun.</h6>
        </blockquote>

        <p>I enjoy learning new things, playing basketball, guitar, and music (especially R&amp;B and hip-hop).</p>

      </div>
    </section><!-- End misc Section -->

    <!-- ======= Contact Section ======= -->
    <section id="contact" class="contact">
      <div class="container">

        <div class="section-title">
          <h2></h2>
          <p>Contact</p>
        </div>
        Collaborations and internships are welcome!
        <p>
          Mail to <a href="mailto:daoyuanchen.cdy@alibaba-inc.com">daoyuanchen.cdy@alibaba-inc.com</a>, <a
            href="mailto:chendaoyuan@pku.edu.cn">chendaoyuan@pku.edu.cn</a>
        </p>
        <a rel="me" href="https://github.com/yxdyc" target="_blank" title="github">
          <svg>
            <image href="assets/github-icon.png" width="50" height="50" />
          </svg>
        </a>
        <a rel="me" href="https://scholar.google.com/citations?hl=en&user=1GdfinUAAAAJ" target="_blank"
          title="google_scholar">
          <svg>
            <image href="assets/scholar-icon.png" width="50" height="50" />
          </svg>
      </div>

    </section><!-- End Contact Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <div class="credits">
      </div>
    </div>
  </footer>

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i
      class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/aos/aos.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>